{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T04:44:18.959662500Z",
     "start_time": "2023-05-10T04:44:17.494882500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "import shutil\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import numpy.random\n",
    "import torch.random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T04:44:20.478878300Z",
     "start_time": "2023-05-10T04:44:19.700827600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# 2023-05-02\n",
    "# For Using GPU (CUDA)\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2023-05-02\n",
    "# For using tensorboard\n",
    "args.istensorboard = False\n",
    "\n",
    "'''\n",
    "Directory setting: ([]: Folder)\n",
    "- [Master directory] (Prerequisite directory)\n",
    "-- Algorithm launcher code (.py, .ipynb, ...) (Prerequisite file)\n",
    "-- [Basic simulation data directory] (data) (Prerequisite directory)\n",
    "--- Simulation data template (Current simulator type: Eclipse, .DATA) (Prerequisite file)\n",
    "--- Simulation permeability set file (.mat, .DATA, ...) (Prerequisite file)\n",
    "-- [Simulation directory] (simulation)\n",
    "--- [Simulation sample directory #f\"Step{num. of algorithm iteration}_Sample{sample number}\"]\n",
    "---- Simulation data file (.DATA): for each Well placement timestep\n",
    "---- Simulation include file (PERMX.DATA, WELL.DATA)\n",
    "---- # File naming convention: f\"{file type}_Sam{sample number}_Seq{timestep index}.DATA\"\n",
    "-- [Variable storage directory] (variables)\n",
    "--- Variable storage.pkl\n",
    "--- Global variable storage.dill\n",
    "-- [Deep learning model storage directory] (model)\n",
    "--- Deep learning model.pkl\n",
    "'''\n",
    "# Modified from J.Y. Kim. (2020)\n",
    "args.master_directory = os.getcwd()\n",
    "args.basicfilepath = 'data'\n",
    "args.simulation_directory = 'simulation'\n",
    "args.variable_save_directory = 'variables'\n",
    "args.deeplearningmodel_save_directory = 'model'\n",
    "args.ecl_filename = '2D_ECL'\n",
    "args.perm_filename = 'PERMX'\n",
    "args.well_filename = 'WELL'\n",
    "\n",
    "args.total_episode = 100\n",
    "args.learning_rate = 0.1 # Learning rate Alpha\n",
    "args.boltzmann_tau = 5.0 # Temperature parameter at Boltzmann policy, Tau\n",
    "args.total_reward = 0\n",
    "args.epsilon = 0.1\n",
    "\n",
    "args.max_iteration = 50 # Maximum iteration num. of algorithm, MAX_STEPS\n",
    "args.sample_num_per_iter = 50 # Simulation sample num. of each iteration of algorithm\n",
    "args.replay_batch = 100 # Replay batch size, B\n",
    "args.nn_update_num = 20 # CNN update number, U: [(1) Constant num. of iteration], (2) Lower limit of loss function value\n",
    "args.batch_size = 20 # Batch size, N\n",
    "args.replay_memory = [] # (1) Using list class, (2) Replay memory class by SLM Lab (page. 105~108)\n",
    "\n",
    "args.gridnum_x = 15\n",
    "args.gridnum_y = 15\n",
    "args.gridsize_x = 120 # ft\n",
    "args.gridsize_y = 120 # ft\n",
    "\n",
    "args.time_step = 120 # days\n",
    "args.total_production_time = 600 # days\n",
    "\n",
    "args.prod_well_num_max = 5\n",
    "args.inj_well_num_max = 0\n",
    "args.total_well_num_max = args.prod_well_num_max + args.inj_well_num_max\n",
    "\n",
    "args.initial_PRESSURE = 3500 # psi\n",
    "args.initial_SOIL = 0.75\n",
    "\n",
    "# 2023-05-02: For reproduction\n",
    "args.random_seed = 202022673\n",
    "random.seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "\n",
    "# For calculation of revenue at each time step\n",
    "args.oil_price = 60 # $/bbl\n",
    "args.water_treatment = 3 # $/bbl\n",
    "args.water_injection = 5 # $/bbl\n",
    "\n",
    "# State: Pressure distribution, Oil saturation, (and Well placement map?)\n",
    "\n",
    "# Action: Well placement (Coordinate of well location)\n",
    "\n",
    "# Environment: Reservoir simulator\n",
    "\n",
    "# Reward: NPV at each time segment\n",
    "\n",
    "args.discount_rate = 0.1 # Used for calculation of NPV\n",
    "args.discount_factor = 1 # Used for Q-value update\n",
    "\n",
    "# Data for State\n",
    "args.input_flag = ('PRESSURE', 'SOIL', 'Well_placement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define Functions (or Methods) and CNN Structure\n",
    "################################### Class: Placement sample ####################################\n",
    "class WellPlacementSample:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.well_loc_map = [[[0 for i in range(0, args.gridnum_x)] for j in range(0, args.gridnum_y)]]\n",
    "        self.well_loc_list = []\n",
    "        self.PRESSURE_map = [[[args.initial_PRESSURE for i in range(0, args.gridnum_x)] for j in range(0, args.gridnum_y)]]\n",
    "        self.SOIL_map = [[[args.initial_SOIL for i in range(0, args.gridnum_x)] for j in range(0, args.gridnum_y)]]\n",
    "        self.income = [0.0]\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "################################# Reading Eclipse Dynamic Data #################################\n",
    "# idx: simulation file index\n",
    "# tstep_idx: simulation time step index\n",
    "# filename: simulation file name\n",
    "# dynamic_type: dynamic data type to collect ('PRESSURE' or 'SOIL')\n",
    "def _read_ecl_prt_2d(args, idx: int, tstep_idx: int, filename: str, dynamic_type: str) -> list:\n",
    "    # Check if dynamic type input is (1) 'PRESSURE', (2) 'SOIL'\n",
    "    if not dynamic_type in ['PRESSURE', 'SOIL']:\n",
    "        print(\"Assign correct dynamic data output type!: 'PRESSURE', 'SOIL'\")\n",
    "        return -1\n",
    "\n",
    "    # File IO\n",
    "    # 1. Open .PRT file\n",
    "    with open(args.simulation_directory+'\\\\'+filename+'_'+str(idx)+'.PRT') as file_read:\n",
    "        line = file_read.readline()\n",
    "        if dynamic_type == 'PRESSURE':\n",
    "            # 2. Find the location of dynamic data (PRESSURE case)\n",
    "            while not line.startswith(f\"  {dynamic_type} AT   {args.time_step * tstep_idx}\"):\n",
    "                line = file_read.readline()\n",
    "            # 3. Dynamic data starts from 10th line below the line [\"  {dynamic_type} AT   {args.time_step * tstep_idx}\"]\n",
    "            for i in range(1,10+1):\n",
    "                line = file_read.readline()\n",
    "            # 4. Collect dynamic data\n",
    "            lines_converted = []\n",
    "            for i in range(1, args.gridnum_y+1):\n",
    "                lines_converted.append([element.strip() for element in line.split()][3::])\n",
    "                line = file_read.readline()\n",
    "        elif dynamic_type == 'SOIL':\n",
    "            # 2. Find the location of dynamic data (SOIL case)\n",
    "            while not line.startswith(f\"  {dynamic_type}     AT   {args.time_step * tstep_idx}\"):\n",
    "                line = file_read.readline()\n",
    "            # 3. Dynamic data starts from 10th line below the line [\"  {dynamic_type}     AT   {args.time_step * tstep_idx}\"]\n",
    "            for i in range(1,10+1):\n",
    "                line = file_read.readline()\n",
    "            # 4. Collect dynamic data\n",
    "            lines_converted = []\n",
    "            for i in range(1, args.gridnum_y+1):\n",
    "                lines_converted.append([element.strip() for element in line.split()][3::])\n",
    "                line = file_read.readline()\n",
    "\n",
    "    # 5. Post-processing (String replacement from (1) '*' to '.', (2) String to Float (Only for 2D)\n",
    "    for i in range(len(lines_converted)):\n",
    "        for j in range(len(lines_converted[i])):\n",
    "            lines_converted[i][j] = float(lines_converted[i][j].replace('*', '.'))\n",
    "\n",
    "    return lines_converted\n",
    "##########################################################################################\n",
    "\n",
    "###################### Reading Eclipse Production or Injection Data ######################\n",
    "# idx: simulation file index\n",
    "# filename: simulation file name\n",
    "# data_type: Production or Injection result data type ('FOPT', 'FWPT', 'FWIT')\n",
    "def _read_ecl_rsm(args, idx: int, filename: str, data_type: str) -> list:\n",
    "    # Check if data type input is (1) 'FOPT', (2) 'FWPT', (3) 'FWIT'\n",
    "    if not data_type in ['FOPT', 'FWPT', 'FWIT']:\n",
    "        print(\"Assign correct output data type!: 'FOPT', 'FWPT', 'FWIT'\")\n",
    "        return -1\n",
    "\n",
    "    # File IO\n",
    "    # 1. Open .RSM file\n",
    "    with open(args.simulation_directory+'\\\\'+filename+'_'+str(idx)+'.RSM') as file_read:\n",
    "        line = file_read.readline()\n",
    "        # 2. Find the location of simulation result data\n",
    "        while not line.startswith(f\" TIME\"):\n",
    "            line = file_read.readline()\n",
    "        # 3. 1st time of simulation result data starts from 6th line below the line [\" TIME\"]\n",
    "        for i in range(1,5+1):\n",
    "            line = file_read.readline()\n",
    "        # 4. Collect production or injection data\n",
    "        lines_converted = []\n",
    "        if data_type == 'FOPT':\n",
    "            for i in range(1, round(args.total_production_time/args.time_step)+1):\n",
    "                lines_converted.append([element.strip() for element in line.split()][2])\n",
    "                line = file_read.readline()\n",
    "        elif data_type == 'FWPT':\n",
    "            for i in range(1, round(args.total_production_time/args.time_step)+1):\n",
    "                lines_converted.append([element.strip() for element in line.split()][3])\n",
    "                line = file_read.readline()\n",
    "        elif data_type == 'FWIT':\n",
    "            for i in range(1, round(args.total_production_time/args.time_step)+1):\n",
    "                lines_converted.append([element.strip() for element in line.split()][4])\n",
    "                line = file_read.readline()\n",
    "\n",
    "    # 5. Post-processing (String replacement from (1) '*' to '.', (2) String to Float)\n",
    "    for i in range(len(lines_converted)):\n",
    "        lines_converted[i] = float(lines_converted[i].replace('*', '.'))\n",
    "\n",
    "    return lines_converted\n",
    "##########################################################################################\n",
    "\n",
    "################################# Running ECL Simulator ##################################\n",
    "# program: 'eclipse' or 'frontsim'\n",
    "# filename: simulation file name (ex. 2D_JY_ECLRUN_1)\n",
    "def _run_program(args, program: str, filename: str):\n",
    "    # Check if dynamic type input is (1) 'eclipse', (2) 'frontsim'\n",
    "    if not program in ['eclipse', 'frontsim']:\n",
    "        print(\"Use correct simulator exe file name!: 'eclipse', 'frontsim'\")\n",
    "        return -1\n",
    "    command = fr\"C:\\\\ecl\\\\2009.1\\\\bin\\\\pc\\\\{program}.exe {filename} > NUL\"\n",
    "    os.chdir(args.simulation_directory)\n",
    "    os.system(command)\n",
    "    os.chdir('../')\n",
    "##########################################################################################\n",
    "\n",
    "###################################### CNN Structure #####################################\n",
    "# class CNN(nn.Module):\n",
    "#     # \"Deep Reinforcement Learning for Generalizable Field Development Optimization\", Jincong He et al, 2021: CNN-based structure\n",
    "#     # \"Reinforcement Learning for Well Location Optimization\", Kshitij Dawar, 2021: ANN\n",
    "#     # Basic structure of He (2021): Convolution-ReLU-Residual block (==Original-Convolution-ReLU-Convolution+Original-ReLU)\n",
    "#     # OR try [basic CNN structure]...\n",
    "#     # argument로 args를 받아와, input_flag가 설정되어 있으면 그 수에 맞게 채널 수를 조정해주고, 없으면 기본값인 3으로 설정됨\n",
    "#     def __init__(self, args):\n",
    "#         super().__init__()\n",
    "#         if args.input_flag: self.num_of_channels = len(args.input_flag)\n",
    "#         else: self.num_of_channels = 2\n",
    "#\n",
    "#         self.layer = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=self.num_of_channels, out_channels=24, kernel_size=(3, 3), padding='same'),\n",
    "#             nn.BatchNorm2d(24),\n",
    "#             nn.ReLU(),\n",
    "#\n",
    "#             # nn.AvgPool2d(stride=2, kernel_size=(2, 2)),\n",
    "#\n",
    "#             nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding='same'),\n",
    "#             nn.BatchNorm2d(48),\n",
    "#             nn.ReLU(),\n",
    "#\n",
    "#             # nn.AvgPool2d(stride=2, kernel_size=(2, 2)),\n",
    "#\n",
    "#             nn.Conv2d(in_channels=48, out_channels=96, kernel_size=(3, 3), padding='same'),\n",
    "#             nn.BatchNorm2d(96),\n",
    "#             nn.ReLU(),\n",
    "#\n",
    "#             # nn.AvgPool2d(stride=2, kernel_size=(2, 2)),\n",
    "#\n",
    "#             nn.Conv2d(in_channels=96, out_channels=24, kernel_size=(3, 3), padding='same'),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#\n",
    "#             # nn.AvgPool2d(stride=2, kernel_size=(2, 2))\n",
    "#\n",
    "#             nn.Conv2d(in_channels=24, out_channels=1, kernel_size=(3, 3), padding='same'),\n",
    "#             nn.BatchNorm2d(1),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#\n",
    "#         self.layer.apply(self._init_weight)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         out = self.layer(x)\n",
    "#         out = torch.nn.Flatten()(out)\n",
    "#         out = self.fc_layer(out)\n",
    "#         return out\n",
    "#\n",
    "#     def _init_weight(self, layer, init_type=\"Xavier\"):\n",
    "#         if isinstance(layer, nn.Conv2d):\n",
    "#             if init_type == \"Xavier\":\n",
    "#                 torch.nn.init.xavier_uniform_(layer.weight)\n",
    "#             elif init_type == \"He\":\n",
    "#                 torch.nn.init.kaiming_uniform_(layer.weight)\n",
    "\n",
    "\n",
    "# https://cryptosalamander.tistory.com/156\n",
    "class BasicBlock(nn.Module):\n",
    "    mul = 1\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding='same', bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding='same', bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        # x를 그대로 더해주기 위함\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        # 만약 size가 안맞아 합연산이 불가하다면, 연산 가능하도록 모양을 맞춰줌\n",
    "        if stride != 1:  # x와\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "        self.conv1.apply(self._init_weight)\n",
    "        self.conv2.apply(self._init_weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)  # 필요에 따라 layer를 Skip\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "    def _init_weight(self, layer, init_type=\"Xavier\"):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            if init_type == \"Xavier\":\n",
    "                torch.nn.init.xavier_uniform_(layer.weight)\n",
    "            elif init_type == \"He\":\n",
    "                torch.nn.init.kaiming_uniform_(layer.weight)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, args, block):\n",
    "        '''\n",
    "        이 두 코드는 형태가 조금 다르다.\n",
    "        == super(MyModule,self).__init__()\n",
    "        == super().__init__()\n",
    "        super 안에 현재 클래스를 명시해준 것과 아닌 것으로 나눌 수 있는데 이는 기능적으론 아무런 차이가 없다.\n",
    "        파생클래스와 self를 넣어서 현재 클래스가 어떤 클래스인지 명확하게 표시 해주는 용도이다.\n",
    "        super(파생클래스, self).__init__()\n",
    "        '''\n",
    "        '''\n",
    "        Structure of DQN\n",
    "        (1) input (gridnum_x*gridnum_y*len(state))\n",
    "        (2) Conv1-BatchNorm-ReLU (gridnum_x*gridnum_y*48)\n",
    "        (3) Residual block (gridnum_x*gridnum_y*48)\n",
    "        (4) Conv2-BatchNorm-ReLU (gridnum_x*gridnum_y*24)\n",
    "        (5) Conv3 (gridnum_x*gridnum_y*1) << Objective: Q-value of each action at current state\n",
    "        Action masking will be done by modified Boltzmann policy\n",
    "        '''\n",
    "        super(DQN, self).__init__()\n",
    "        if args.input_flag: self.num_of_channels = len(args.input_flag)\n",
    "        else: self.num_of_channels = 3\n",
    "\n",
    "        self.in_planes = 0\n",
    "        self.out_channel = 48\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.num_of_channels, out_channels=self.out_channel, kernel_size=3, stride=1, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channel)\n",
    "\n",
    "        self.layer1 = self.make_layer(block=block, out_planes=self.out_channel, num_blocks=1, stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.out_channel, out_channels=round(self.out_channel/2), kernel_size=3, stride=1, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(round(self.out_channel/2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=round(self.out_channel/2), out_channels=1, kernel_size=3, stride=1, padding='same')\n",
    "\n",
    "        self.conv1.apply(self._init_weight)\n",
    "        self.conv2.apply(self._init_weight)\n",
    "        self.conv3.apply(self._init_weight)\n",
    "\n",
    "    def make_layer(self, block, out_planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(block(self.in_planes, out_planes, strides[i]))\n",
    "            self.in_planes = block.mul * out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "    def _init_weight(self, layer, init_type=\"Xavier\"):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            if init_type == \"Xavier\":\n",
    "                torch.nn.init.xavier_uniform_(layer.weight)\n",
    "            elif init_type == \"He\":\n",
    "                torch.nn.init.kaiming_uniform_(layer.weight)\n",
    "##########################################################################################\n",
    "\n",
    "#################################### Boltzmann policy ####################################\n",
    "def _Boltzmann_policy(args, Q_value: list, well_placement: list) -> list:\n",
    "    exp_tau = deepcopy(Q_value)\n",
    "    probability = deepcopy(Q_value)\n",
    "\n",
    "    # Preventing overflow error\n",
    "    max_Q_value = np.array(Q_value).flatten().max()\n",
    "\n",
    "    # Get exponential of all elements in Q_value\n",
    "    for i in range(0, len(Q_value)):\n",
    "        for j in range(0, len(Q_value[i])):\n",
    "            exp_tau[i][j] = np.exp((exp_tau[i][j]-max_Q_value)/args.boltzmann_tau)\n",
    "\n",
    "    # Calculating probability map\n",
    "    for i in range(0, len(Q_value)):\n",
    "        for j in range(0, len(Q_value[i])):\n",
    "            probability[i][j] = exp_tau[i][j] / np.concatenate(np.array(exp_tau)).sum()\n",
    "\n",
    "    # Masking probability map: Setting probability = 0 where wells were already exists,\n",
    "    # and Scaling the rest of probability map\n",
    "    probability = [[0 if well_placement[i][j] != 0 else probability[i][j] for j in range(len(Q_value[i]))] for i in range(len(Q_value))]\n",
    "    probability = [[(probability[i][j]/np.concatenate(np.array(probability)).sum()) for j in range(len(Q_value[i]))] for i in range(len(Q_value))]\n",
    "\n",
    "    return probability\n",
    "##########################################################################################\n",
    "\n",
    "#################################### Action Selection ####################################\n",
    "def _select_well_loc(args, probability: list) -> tuple:\n",
    "    # Create cumulative probability function with given probability map by policy\n",
    "    cumsum_prob = np.cumsum(probability)\n",
    "    CDF = np.append([0], cumsum_prob)\n",
    "\n",
    "    # Generate random number (0~1)\n",
    "    CDF_prob = random.random()\n",
    "    # # For debugging\n",
    "    # print(CDF_prob)\n",
    "\n",
    "    # Find corresponding well location\n",
    "    for i in range(0, len(CDF)-1):\n",
    "        if (CDF_prob >= CDF[i]) and (CDF_prob < CDF[i+1]):\n",
    "            well_loc = ((i%args.gridnum_x)+1, (i//args.gridnum_x)+1) # (x, y) for ECL, (Row, Col) for Python.\n",
    "            return well_loc\n",
    "\n",
    "    # # For debugging\n",
    "    print(\"Well location selection was not appropriately done!\")\n",
    "##########################################################################################\n",
    "\n",
    "#################################### NPV Calculation #####################################\n",
    "def _calculate_income(args, tstep_idx: int, FOPT: list, FWPT: list, FWIT: list) -> float:\n",
    "    # Calculate income from [tstep_idx] to [tstep_idx+1]\n",
    "    # e.g. tstep_idx == 0 >> income of 0 ~ 120 day, tstep_idx == 1 >> income of 120 ~ 240 day\n",
    "    oil_income = (FOPT[tstep_idx+1] - FOPT[tstep_idx]) * args.oil_price / (((1 + args.discount_rate)) ** (args.time_step * (tstep_idx + 1) / 365))\n",
    "    water_treat = (FWPT[tstep_idx+1] - FWPT[tstep_idx]) * args.water_treatment / (((1 + args.discount_rate)) ** (args.time_step * (tstep_idx + 1) / 365))\n",
    "    water_inj = (FWIT[tstep_idx+1] - FWIT[tstep_idx]) * args.water_injection / (((1 + args.discount_rate)) ** (args.time_step * (tstep_idx + 1) / 365))\n",
    "\n",
    "    income = oil_income - water_treat - water_inj\n",
    "\n",
    "    return income\n",
    "##########################################################################################\n",
    "\n",
    "############################ Generating Simulation Data File #############################\n",
    "def _ecl_data_generate(args, algorithm_iter_count: int, sample_num: int, timestep: int, well_loc_list: list[tuple]) -> None:\n",
    "    output_data_file = []\n",
    "    output_perm_file = []\n",
    "    output_well_file = []\n",
    "\n",
    "    # Read and modify simulation data template on Python\n",
    "    with open(f\"{os.path.join(args.basicfilepath, args.ecl_filename)}.template\", 'r') as file_read_data:\n",
    "        line = file_read_data.readline()\n",
    "        output_data_file.append(line)\n",
    "        while not line.startswith(\"[#PERMX]\"):\n",
    "            line = file_read_data.readline()\n",
    "            output_data_file.append(line)\n",
    "        line = line.replace(\"[#PERMX]\", f\"\\'{args.perm_filename}_Sam{sample_num}_Seq{timestep}.DATA\\'\")\n",
    "        output_data_file[-1] = line\n",
    "        while not line.startswith(\"[#WELL]\"):\n",
    "            line = file_read_data.readline()\n",
    "            output_data_file.append(line)\n",
    "        line = line.replace(\"[#WELL]\", f\"\\'{args.well_filename}_Sam{sample_num}_Seq{timestep}.DATA\\'\")\n",
    "        output_data_file[-1] = line\n",
    "        while line:\n",
    "            line = file_read_data.readline()\n",
    "            output_data_file.append(line)\n",
    "\n",
    "    # Read permeability file\n",
    "    with open(f\"{os.path.join(args.basicfilepath, args.perm_filename)}.template\", 'r') as file_read_perm:\n",
    "        while line:\n",
    "            line = file_read_perm.readline()\n",
    "            output_perm_file.append(line)\n",
    "\n",
    "    # Write simulation main data and include files\n",
    "    sample_simulation_directory = f\"Step{algorithm_iter_count}_Sample{sample_num}\"\n",
    "    sample_data_name = f\"{args.ecl_filename}_Sam{sample_num}_Seq{timestep}.DATA\"\n",
    "    sample_perm_name = f\"{args.perm_filename}_Sam{sample_num}_Seq{timestep}.DATA\"\n",
    "    sample_well_name = f\"{args.well_filename}_Sam{sample_num}_Seq{timestep}.DATA\"\n",
    "\n",
    "    with open(f\"{os.path.join(args.simulation_directory, sample_simulation_directory, sample_data_name)}\", 'w') as file_write_data:\n",
    "        for i in range(len(output_data_file)):\n",
    "            file_write_data.write(output_data_file[i])\n",
    "\n",
    "    with open(f\"{os.path.join(args.simulation_directory, sample_simulation_directory, sample_perm_name)}\", 'w') as file_write_perm:\n",
    "        for i in range(len(output_perm_file)):\n",
    "            file_write_data.write(output_perm_file[i])\n",
    "\n",
    "    for i in range(len(well_loc_list)):\n",
    "        output_well_file.append(f\"--WELL #{i+1}\\n\"\n",
    "                                f\"WELSPECS\\n P{i+1} ALL {well_loc_list[i][0]} {well_loc_list[i][1]} 1* LIQ 3* NO /\\n /\\n \\n\"\n",
    "                                f\"COMPDAT\\n P{i+1} {well_loc_list[i][0]} {well_loc_list[i][1]} 1 1 1* 1* 1* 1 1* 1* 1* Z /\\n /\\n \\n\"\n",
    "                                f\"WCONPROD\\n P{i+1} 1* BHP 5000 4* 1500.0 /\\n /\\n \\n\"\n",
    "                                f\"TSTEP\\n 1*{args.time_step} /\\n \\n \\n\")\n",
    "\n",
    "    with open(f\"{os.path.join(args.simulation_directory, sample_simulation_directory, sample_well_name)}\", 'w') as file_write_well:\n",
    "        for i in range(len(output_well_file)):\n",
    "            file_write_well.write(output_well_file[i])\n",
    "##########################################################################################\n",
    "\n",
    "######################################## Sampler #########################################\n",
    "def _sampler(args, algorithm_iter_count: int, sample_num: int, network)-> WellPlacementSample:\n",
    "    well_placement_sample = WellPlacementSample()\n",
    "\n",
    "    Q_network = network\n",
    "\n",
    "    if not os.path.exists(os.path.join(args.simulation_directory, f\"Step{algorithm_iter_count}_Sample{sample_num}\")):\n",
    "        os.mkdir(os.path.join(args.simulation_directory, f\"Step{algorithm_iter_count}_Sample{sample_num}\"))\n",
    "\n",
    "    # Well placement sampling\n",
    "    for time_step in range(0, args.total_well_num_max):\n",
    "        # Inference of Q-value from PRESSURE, SOIL, and Well placement\n",
    "        Q_map = Q_network([well_placement_sample.PRESSURE_map[time_step], well_placement_sample.SOIL_map[time_step], well_placement_sample.well_loc_map[time_step]])\n",
    "\n",
    "        # Calculate well placement probability and Specify well location\n",
    "        prob = _Boltzmann_policy(args=args, Q_value=Q_map, well_placement=well_placement_sample.well_loc_map[time_step])\n",
    "        well_loc = _select_well_loc(args=args, probability=prob)\n",
    "        WellPlacementSample.well_loc_list.append(well_loc)\n",
    "\n",
    "        # Generate and run simulation file\n",
    "        _ecl_data_generate(args=args, algorithm_iter_count=algorithm_iter_count, sample_num=sample_num, timestep=time_step, well_loc_list=WellPlacementSample.well_loc_list)\n",
    "\n",
    "        os.chdir(os.path.join(args.simulation_directory, f\"Step{algorithm_iter_count}_Sample{sample_num}\"))\n",
    "        _run_program(args=args, program='eclipse', filename=f\"{args.ecl_filename}_Sam{sample_num}_Seq{time_step}\")\n",
    "\n",
    "        # Read PRESSURE, SOIL map\n",
    "        # Inference of Q-value with Q-network by PRESSURE/SOIL/Well placement map\n",
    "        # Append PRESSURE map, SOIL map, Well placement map, Income\n",
    "\n",
    "    return well_placement_sample\n",
    "##########################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T08:27:27.135349700Z",
     "start_time": "2023-05-10T08:27:27.053331700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Directory setting\n",
    "if not os.path.exists(args.simulation_directory):\n",
    "    print('Simulation directory does not exists: Created Simulation directory\\n')\n",
    "    os.mkdir(args.simulation_directory)\n",
    "\n",
    "if not os.path.exists(args.variable_save_directory):\n",
    "    print('Variable storage directory does not exists: Created Variable storage directory\\n')\n",
    "    os.mkdir(args.variable_save_directory)\n",
    "\n",
    "if not os.path.exists(args.deeplearningmodel_save_directory):\n",
    "    print('Deep learning model storage directory does not exists: Created Deep learning model storage directory\\n')\n",
    "    os.mkdir(args.deeplearningmodel_save_directory)\n",
    "\n",
    "# Implementation of DQN Algorithm\n",
    "# Initialize Deep Q Network\n",
    "Deep_Q_Network = DQN(args=args, block=BasicBlock)\n",
    "\n",
    "for m in range(1, args.max_iteration):\n",
    "\n",
    "    # Collect h experience (s, a, r, s') with current policy and save at replay memory\n",
    "    # 1. Generate Simulation examples with current policy (sample_num: int)\n",
    "    # 2. Read and save (1) Pressure, Oil saturation map at current time step (s), (2) Well placement at current time step (a),\n",
    "    # (3) NPV at current time step, and (4) Pressure, Oil saturation map at next time step\n",
    "    # 읽어온 자료를 DataLoader 형식으로 바꿔야 함\n",
    "    for b in range(1, args.replay_batch):\n",
    "        # Extract b-th experience data from replay memory\n",
    "        for u in range(1, args.nn_update_num):\n",
    "            for i in range(1, args.batch_size):\n",
    "                pass\n",
    "                # Calculate Target Q-value for all samples in b-th batch experience\n",
    "                # if well_num == 5 (terminal state): # If you want to know that current state is terminal state, then well placement map should be required?\n",
    "                #   yi = ri\n",
    "                # elif well_num < 5 (non-terminal state):\n",
    "                #   yi = ri + args.discount_factor * max.a'(Q_network(s', a'))\n",
    "            # Loss calculation: L(theta) = sum((yi - Q_network(s', a'))^2) / args.batch_size\n",
    "            # Update Q-network parameter: theta = theta - args.learning_rate * grad(L(theta))\n",
    "    # Decrease tau (temperature parameter of Boltzmann policy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T02:05:58.656199Z",
     "start_time": "2023-05-09T02:05:58.489161900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Return & Visualize Optimization result\n",
    "# Final well placement\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare PSO Result & DQN Result\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'H:\\\\Lab_Meeting\\\\Simulation_Model\\\\2D_15-by-15_DQN'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T23:35:33.421073200Z",
     "start_time": "2023-05-09T23:35:33.344055700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation directory does not exists: Created Simulation directory\n",
      "\n",
      "Variable storage directory does not exists: Created Variable storage directory\n",
      "\n",
      "Deep learning model storage directory does not exists: Created Deep learning model storage directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(args.simulation_directory):\n",
    "    print('Simulation directory does not exists: Created Simulation directory\\n')\n",
    "    os.mkdir(args.simulation_directory)\n",
    "\n",
    "if not os.path.exists(args.variable_save_directory):\n",
    "    print('Variable storage directory does not exists: Created Variable storage directory\\n')\n",
    "    os.mkdir(args.variable_save_directory)\n",
    "\n",
    "if not os.path.exists(args.deeplearningmodel_save_directory):\n",
    "    print('Deep learning model storage directory does not exists: Created Deep learning model storage directory\\n')\n",
    "    os.mkdir(args.deeplearningmodel_save_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T23:48:56.234678100Z",
     "start_time": "2023-05-09T23:48:56.153659600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# os.chdir(\"./2D_15-by-15_DQN\")\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\Lab_Meeting\\Simulation_Model\\\\2D_15-by-15_DQN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T02:01:48.582756200Z",
     "start_time": "2023-05-10T02:01:48.502738100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "'H:\\\\Lab_Meeting'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T02:07:35.636595900Z",
     "start_time": "2023-05-10T02:07:35.555578100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(os.getcwd(), \"test\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T01:56:03.119290Z",
     "start_time": "2023-05-10T01:56:03.038271600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
